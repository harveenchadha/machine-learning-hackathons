{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(df.info())\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 21 columns):\n",
      "serial number       800 non-null int64\n",
      "account_info        800 non-null object\n",
      "duration_month      800 non-null int64\n",
      "credit_history      800 non-null object\n",
      "purpose             800 non-null object\n",
      "credit_amount       800 non-null int64\n",
      "savings_account     800 non-null object\n",
      "employment_st       800 non-null object\n",
      "poi                 800 non-null int64\n",
      "personal_status     800 non-null object\n",
      "gurantors           800 non-null object\n",
      "resident_since      800 non-null int64\n",
      "property_type       800 non-null object\n",
      "age                 800 non-null int64\n",
      "installment_type    800 non-null object\n",
      "housing_type        800 non-null object\n",
      "credits_no          800 non-null int64\n",
      "job_type            800 non-null object\n",
      "liables             800 non-null int64\n",
      "telephone           800 non-null object\n",
      "foreigner           800 non-null object\n",
      "dtypes: int64(8), object(13)\n",
      "memory usage: 131.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial number</th>\n",
       "      <th>account_info</th>\n",
       "      <th>duration_month</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>employment_st</th>\n",
       "      <th>poi</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>...</th>\n",
       "      <th>resident_since</th>\n",
       "      <th>property_type</th>\n",
       "      <th>age</th>\n",
       "      <th>installment_type</th>\n",
       "      <th>housing_type</th>\n",
       "      <th>credits_no</th>\n",
       "      <th>job_type</th>\n",
       "      <th>liables</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreigner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial number account_info  duration_month credit_history purpose  \\\n",
       "0              1          A11               6            A34     A43   \n",
       "1              2          A12              48            A32     A43   \n",
       "2              3          A14              12            A34     A46   \n",
       "3              4          A11              42            A32     A42   \n",
       "4              5          A11              24            A33     A40   \n",
       "\n",
       "   credit_amount savings_account employment_st  poi personal_status    ...     \\\n",
       "0           1169             A65           A75    4             A93    ...      \n",
       "1           5951             A61           A73    2             A92    ...      \n",
       "2           2096             A61           A74    2             A93    ...      \n",
       "3           7882             A61           A74    2             A93    ...      \n",
       "4           4870             A61           A73    3             A93    ...      \n",
       "\n",
       "  resident_since  property_type age  installment_type housing_type credits_no  \\\n",
       "0              4           A121  67              A143         A152          2   \n",
       "1              2           A121  22              A143         A152          1   \n",
       "2              3           A121  49              A143         A152          1   \n",
       "3              4           A122  45              A143         A153          1   \n",
       "4              4           A124  53              A143         A153          2   \n",
       "\n",
       "   job_type liables  telephone foreigner  \n",
       "0      A173       1       A192      A201  \n",
       "1      A173       1       A191      A201  \n",
       "2      A172       2       A191      A201  \n",
       "3      A173       2       A191      A201  \n",
       "4      A173       2       A191      A201  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv_file('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_cols = [ 'account_info' , 'credit_history' , 'purpose' , 'savings_account', 'employment_st', 'personal_status', 'gurantors', 'property_type' ,'installment_type' ,'housing_type' ,'job_type', 'telephone' , 'foreigner' , 'serial number' , 'duration_month',  'poi' , 'resident_since' , 'age', 'credits_no', 'liables', 'credit_amount']\n",
    "len(fil_cols)\n",
    "new_fil_cols =[ 'account_info' , 'credit_history' , 'purpose' , 'savings_account', 'employment_st',  'gurantors', 'property_type' ,'installment_type' ,'housing_type' ,'job_type' , 'foreigner' , 'serial number' , 'duration_month',  'poi' , 'resident_since' , 'age', 'credits_no', 'liables', 'credit_amount']\n",
    "new_val_cols =[ 'account_info' , 'credit_history' , 'purpose' , 'savings_account', 'employment_st',  'gurantors', 'property_type' ,'installment_type' ,'housing_type' ,'job_type' , 'foreigner' , 'serial number' , 'duration_month',  'poi' , 'resident_since' , 'age', 'credits_no', 'liables']\n",
    "\n",
    "val_cols = [ 'account_info' , 'credit_history' , 'purpose' , 'savings_account', 'employment_st', 'personal_status', 'gurantors', 'property_type' ,'installment_type' ,'housing_type' ,'job_type', 'telephone' , 'foreigner' , 'serial number' , 'duration_month',  'poi' , 'resident_since' , 'age', 'credits_no', 'liables']\n",
    "obj_cols = [ 'account_info' , 'credit_history' , 'purpose' , 'savings_account', 'employment_st', 'personal_status', 'gurantors', 'property_type' ,'installment_type' ,'housing_type' ,'job_type', 'telephone' , 'foreigner' ]\n",
    "\n",
    "new_obj_cols = [ 'account_info' , 'credit_history' , 'purpose' , 'savings_account', 'employment_st',  'gurantors', 'property_type' ,'installment_type' ,'housing_type' ,'job_type' , 'foreigner' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_columns(fil_cols, df):\n",
    "    df =df[fil_cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =reorder_columns(fil_cols, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_info</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>employment_st</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>gurantors</th>\n",
       "      <th>property_type</th>\n",
       "      <th>installment_type</th>\n",
       "      <th>housing_type</th>\n",
       "      <th>...</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreigner</th>\n",
       "      <th>serial number</th>\n",
       "      <th>duration_month</th>\n",
       "      <th>poi</th>\n",
       "      <th>resident_since</th>\n",
       "      <th>age</th>\n",
       "      <th>credits_no</th>\n",
       "      <th>liables</th>\n",
       "      <th>credit_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>...</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>...</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>...</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>A122</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>...</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>A124</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>...</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_info credit_history purpose savings_account employment_st  \\\n",
       "0          A11            A34     A43             A65           A75   \n",
       "1          A12            A32     A43             A61           A73   \n",
       "2          A14            A34     A46             A61           A74   \n",
       "3          A11            A32     A42             A61           A74   \n",
       "4          A11            A33     A40             A61           A73   \n",
       "\n",
       "  personal_status gurantors property_type installment_type housing_type  \\\n",
       "0             A93      A101          A121             A143         A152   \n",
       "1             A92      A101          A121             A143         A152   \n",
       "2             A93      A101          A121             A143         A152   \n",
       "3             A93      A103          A122             A143         A153   \n",
       "4             A93      A101          A124             A143         A153   \n",
       "\n",
       "       ...       telephone foreigner serial number  duration_month  poi  \\\n",
       "0      ...            A192      A201             1               6    4   \n",
       "1      ...            A191      A201             2              48    2   \n",
       "2      ...            A191      A201             3              12    2   \n",
       "3      ...            A191      A201             4              42    2   \n",
       "4      ...            A191      A201             5              24    3   \n",
       "\n",
       "   resident_since  age  credits_no  liables  credit_amount  \n",
       "0               4   67           2        1           1169  \n",
       "1               2   22           1        1           5951  \n",
       "2               3   49           1        2           2096  \n",
       "3               4   45           1        2           7882  \n",
       "4               4   53           2        2           4870  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['credit_amount'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df , columns):\n",
    "    new_df = df.drop(columns =columns, axis = 1)\n",
    "    return new_df\n",
    "columns_to_be_dropped = ['serial number']\n",
    "new_df = drop_columns(df, columns_to_be_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.get_dummies(new_df, columns = obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_month</th>\n",
       "      <th>poi</th>\n",
       "      <th>resident_since</th>\n",
       "      <th>age</th>\n",
       "      <th>credits_no</th>\n",
       "      <th>liables</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>account_info_A11</th>\n",
       "      <th>account_info_A12</th>\n",
       "      <th>account_info_A13</th>\n",
       "      <th>...</th>\n",
       "      <th>housing_type_A152</th>\n",
       "      <th>housing_type_A153</th>\n",
       "      <th>job_type_A171</th>\n",
       "      <th>job_type_A172</th>\n",
       "      <th>job_type_A173</th>\n",
       "      <th>job_type_A174</th>\n",
       "      <th>telephone_A191</th>\n",
       "      <th>telephone_A192</th>\n",
       "      <th>foreigner_A201</th>\n",
       "      <th>foreigner_A202</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4870</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration_month  poi  resident_since  age  credits_no  liables  \\\n",
       "0               6    4               4   67           2        1   \n",
       "1              48    2               2   22           1        1   \n",
       "2              12    2               3   49           1        2   \n",
       "3              42    2               4   45           1        2   \n",
       "4              24    3               4   53           2        2   \n",
       "\n",
       "   credit_amount  account_info_A11  account_info_A12  account_info_A13  \\\n",
       "0           1169                 1                 0                 0   \n",
       "1           5951                 0                 1                 0   \n",
       "2           2096                 0                 0                 0   \n",
       "3           7882                 1                 0                 0   \n",
       "4           4870                 1                 0                 0   \n",
       "\n",
       "        ...        housing_type_A152  housing_type_A153  job_type_A171  \\\n",
       "0       ...                        1                  0              0   \n",
       "1       ...                        1                  0              0   \n",
       "2       ...                        1                  0              0   \n",
       "3       ...                        0                  1              0   \n",
       "4       ...                        0                  1              0   \n",
       "\n",
       "   job_type_A172  job_type_A173  job_type_A174  telephone_A191  \\\n",
       "0              0              1              0               0   \n",
       "1              0              1              0               1   \n",
       "2              1              0              0               1   \n",
       "3              0              1              0               1   \n",
       "4              0              1              0               1   \n",
       "\n",
       "   telephone_A192  foreigner_A201  foreigner_A202  \n",
       "0               1               1               0  \n",
       "1               0               1               0  \n",
       "2               0               1               0  \n",
       "3               0               1               0  \n",
       "4               0               1               0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = new_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(new_df):\n",
    "    labels = new_df['credit_amount']\n",
    "    X = drop_columns(new_df,'credit_amount')\n",
    "    return np.array(X), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X , y = getFeatures(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 60), (800,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([60,  4,  2, 27,  1,  1,  0,  1,  0,  0,  0,  0,  1,  0,  0,  1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  1,\n",
       "         0,  0,  0,  0,  1,  0,  1,  1,  0]), 14027)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] ,y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size =0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((720, 60), (720,), (80, 60), (80,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , y_train.shape , X_valid.shape , y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca= PCA()\n",
    "# pca.fit(X_train)\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_valid = pca.transform(X_valid)\n",
    "\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((720, 60), (80, 60))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_valid = scale.transform(X_valid)\n",
    "X_train.shape, X_valid.shape\n",
    "# y_valid_scaled = scale_y.transform(y_valid_new)\n",
    "# #y_valid = minmax(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_new = y_train.reshape(-1,1)\n",
    "# y_valid_new = y_valid.reshape(-1,1)\n",
    "# y_train_new.shape,y_valid_new.shape\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scale_y = MinMaxScaler()\n",
    "# scale_y.fit(y_train_new)\n",
    "# y_train_scaled = scale_y.transform(y_train_new)\n",
    "# y_valid_scaled = scale_y.transform(y_valid_new)\n",
    "# #y_valid = minmax(y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_scaled[3] , y_valid_scaled[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "def print_summary(classifier , X_valid, y_valid):\n",
    "    prediction = classifier.predict(X_valid)\n",
    "    print( math.sqrt(mean_squared_error(y_valid, prediction)))\n",
    "    \n",
    "    \n",
    "def print_summary_new(prediction , y_valid):\n",
    "    \n",
    "    print(accuracy_score(y_valid, prediction))\n",
    "    print(classification_report(y_valid, prediction))\n",
    "    print(confusion_matrix(y_valid, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn import tree \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_default_classifiers(X_train, y_train, X_valid, y_valid):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    classifier_rf = RandomForestRegressor()\n",
    "    classifier_rf.fit(X_train, y_train)\n",
    "    print(\"For Random Forests:\\n\")\n",
    "    print_summary(classifier_rf, X_valid, y_valid)\n",
    "    \n",
    "    \n",
    "    classifier_svc = SVR()\n",
    "    classifier_svc.fit(X_train, y_train)\n",
    "    print(\"For SVC:\\n\")\n",
    "    print_summary( classifier_svc, X_valid, y_valid)\n",
    "    \n",
    "    \n",
    "    classifier_knn = KNeighborsRegressor()\n",
    "    classifier_knn.fit(X_train, y_train)\n",
    "    print(\"For KNN:\\n\")\n",
    "    print_summary( classifier_knn, X_valid, y_valid)\n",
    "    \n",
    "    classifier_ada = AdaBoostRegressor()\n",
    "    classifier_ada.fit(X_train, y_train)\n",
    "    print(\"For Adaboost:\\n\")\n",
    "    print_summary( classifier_ada, X_valid, y_valid)\n",
    "    \n",
    "    classifier_gbc = GradientBoostingRegressor()\n",
    "    classifier_gbc.fit(X_train, y_train)\n",
    "    print(\"For Gradient Boosting:\\n\")\n",
    "    print_summary( classifier_gbc, X_valid, y_valid)\n",
    "    \n",
    "    classifier_xgb = XGBRegressor()\n",
    "    classifier_xgb.fit(X_train, y_train)\n",
    "    print(\"For XG Boosting:\\n\")\n",
    "    print_summary( classifier_xgb, X_valid, y_valid)\n",
    "    \n",
    "    return [classifier_ada,classifier_gbc,classifier_xgb]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forests:\n",
      "\n",
      "1888.3001004954826\n",
      "For SVC:\n",
      "\n",
      "3057.5577232922146\n",
      "For KNN:\n",
      "\n",
      "2972.052348041669\n",
      "For Adaboost:\n",
      "\n",
      "2206.4538799339894\n",
      "For Gradient Boosting:\n",
      "\n",
      "1822.6265395792975\n",
      "For XG Boosting:\n",
      "\n",
      "1751.5222037092635\n"
     ]
    }
   ],
   "source": [
    "classifier_list = try_default_classifiers(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/root/miniconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Flatten,Dense,Dropout, Activation, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return (K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Lambda(lambda x: x , input_shape = (24)))\n",
    "#model.add(Lambda(lambda x: x+0.1 , input_shape = (64,64,3)))\n",
    "#model.add(Flatten())\n",
    "model.add(BatchNormalization(input_shape=(60,)))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer = 'Adam' , loss = root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/500\n",
      "720/720 [==============================] - 1s 1ms/step - loss: 3225.0150 - val_loss: 2881.5141\n",
      "Epoch 2/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 3223.1686 - val_loss: 2880.0146\n",
      "Epoch 3/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 3220.9874 - val_loss: 2877.7644\n",
      "Epoch 4/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 3217.7128 - val_loss: 2873.7962\n",
      "Epoch 5/500\n",
      "720/720 [==============================] - 0s 137us/step - loss: 3212.4074 - val_loss: 2865.6564\n",
      "Epoch 6/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 3201.7729 - val_loss: 2847.3424\n",
      "Epoch 7/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 3177.7680 - val_loss: 2804.1866\n",
      "Epoch 8/500\n",
      "720/720 [==============================] - 0s 127us/step - loss: 3122.9571 - val_loss: 2694.6746\n",
      "Epoch 9/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 3009.5549 - val_loss: 2461.1390\n",
      "Epoch 10/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 2810.4157 - val_loss: 2180.3256\n",
      "Epoch 11/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 2551.9141 - val_loss: 1975.0267\n",
      "Epoch 12/500\n",
      "720/720 [==============================] - 0s 130us/step - loss: 2279.9209 - val_loss: 1851.6260\n",
      "Epoch 13/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 2052.4162 - val_loss: 1743.0613\n",
      "Epoch 14/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1882.0769 - val_loss: 1642.3168\n",
      "Epoch 15/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1717.7104 - val_loss: 1570.8656\n",
      "Epoch 16/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1582.5847 - val_loss: 1501.9426\n",
      "Epoch 17/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1500.9576 - val_loss: 1429.3649\n",
      "Epoch 18/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1483.8966 - val_loss: 1371.3872\n",
      "Epoch 19/500\n",
      "720/720 [==============================] - 0s 138us/step - loss: 1439.6303 - val_loss: 1314.3784\n",
      "Epoch 20/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1401.7192 - val_loss: 1263.4202\n",
      "Epoch 21/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1323.7598 - val_loss: 1240.9724\n",
      "Epoch 22/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1343.7404 - val_loss: 1235.0634\n",
      "Epoch 23/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1334.7221 - val_loss: 1213.4649\n",
      "Epoch 24/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1310.8266 - val_loss: 1181.3578\n",
      "Epoch 25/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1259.8731 - val_loss: 1180.2376\n",
      "Epoch 26/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1232.4900 - val_loss: 1170.0567\n",
      "Epoch 27/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1231.0609 - val_loss: 1160.7099\n",
      "Epoch 28/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1247.5498 - val_loss: 1153.6992\n",
      "Epoch 29/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1262.7527 - val_loss: 1149.4402\n",
      "Epoch 30/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1165.9126 - val_loss: 1148.3593\n",
      "Epoch 31/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1228.8184 - val_loss: 1137.6306\n",
      "Epoch 32/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1288.2781 - val_loss: 1134.0778\n",
      "Epoch 33/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1226.2938 - val_loss: 1118.8218\n",
      "Epoch 34/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1202.2942 - val_loss: 1108.0877\n",
      "Epoch 35/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1202.7897 - val_loss: 1120.1272\n",
      "Epoch 36/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1178.0755 - val_loss: 1107.9128\n",
      "Epoch 37/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1182.9945 - val_loss: 1109.7608\n",
      "Epoch 38/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1186.2939 - val_loss: 1093.2036\n",
      "Epoch 39/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1154.8393 - val_loss: 1086.8337\n",
      "Epoch 40/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1161.4333 - val_loss: 1101.6768\n",
      "Epoch 41/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1211.6294 - val_loss: 1091.1301\n",
      "Epoch 42/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1150.6296 - val_loss: 1067.2753\n",
      "Epoch 43/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1145.5787 - val_loss: 1082.3636\n",
      "Epoch 44/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1114.1302 - val_loss: 1063.0838\n",
      "Epoch 45/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1216.4315 - val_loss: 1048.3605\n",
      "Epoch 46/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1124.4486 - val_loss: 1058.4781\n",
      "Epoch 47/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 1145.1611 - val_loss: 1060.9400\n",
      "Epoch 48/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1143.2438 - val_loss: 1052.8824\n",
      "Epoch 49/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1139.6500 - val_loss: 1060.2102\n",
      "Epoch 50/500\n",
      "720/720 [==============================] - 0s 126us/step - loss: 1103.5888 - val_loss: 1042.0881\n",
      "Epoch 51/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1167.0651 - val_loss: 1071.4844\n",
      "Epoch 52/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1218.9789 - val_loss: 1080.0451\n",
      "Epoch 53/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1148.8521 - val_loss: 1032.1770\n",
      "Epoch 54/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1167.0362 - val_loss: 1037.7727\n",
      "Epoch 55/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1149.2582 - val_loss: 1031.4376\n",
      "Epoch 56/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1134.3085 - val_loss: 1030.6016\n",
      "Epoch 57/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1132.5927 - val_loss: 1029.2474\n",
      "Epoch 58/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1148.0163 - val_loss: 1018.3355\n",
      "Epoch 59/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1097.2723 - val_loss: 1006.3618\n",
      "Epoch 60/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1126.3576 - val_loss: 999.8631\n",
      "Epoch 61/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1100.0554 - val_loss: 996.1605\n",
      "Epoch 62/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1092.5809 - val_loss: 1009.7078\n",
      "Epoch 63/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1112.3076 - val_loss: 1004.1444\n",
      "Epoch 64/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1115.3998 - val_loss: 998.2318\n",
      "Epoch 65/500\n",
      "720/720 [==============================] - 0s 126us/step - loss: 1089.8848 - val_loss: 995.0049\n",
      "Epoch 66/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1126.9376 - val_loss: 1006.2526\n",
      "Epoch 67/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1099.3718 - val_loss: 1020.7962\n",
      "Epoch 68/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1053.2482 - val_loss: 1016.4729\n",
      "Epoch 69/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1128.1554 - val_loss: 1025.6299\n",
      "Epoch 70/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1016.6063 - val_loss: 1018.9392\n",
      "Epoch 71/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1080.3072 - val_loss: 1018.1603\n",
      "Epoch 72/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1107.7238 - val_loss: 1012.4163\n",
      "Epoch 73/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1069.2381 - val_loss: 1005.4569\n",
      "Epoch 74/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1101.8352 - val_loss: 993.7742\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 117us/step - loss: 1062.9798 - val_loss: 1002.7246\n",
      "Epoch 76/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1065.7615 - val_loss: 1004.3718\n",
      "Epoch 77/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1090.7539 - val_loss: 990.7930\n",
      "Epoch 78/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1076.6033 - val_loss: 986.4801\n",
      "Epoch 79/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 1081.4509 - val_loss: 985.3178\n",
      "Epoch 80/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1031.9945 - val_loss: 996.1372\n",
      "Epoch 81/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1036.4030 - val_loss: 1007.5117\n",
      "Epoch 82/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1100.5463 - val_loss: 1007.4146\n",
      "Epoch 83/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 1053.1306 - val_loss: 1014.9454\n",
      "Epoch 84/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1027.3341 - val_loss: 1016.7671\n",
      "Epoch 85/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1067.3461 - val_loss: 1005.2163\n",
      "Epoch 86/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1052.0741 - val_loss: 992.6018\n",
      "Epoch 87/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 1076.3316 - val_loss: 989.2202\n",
      "Epoch 88/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1068.1853 - val_loss: 988.9388\n",
      "Epoch 89/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 1085.9640 - val_loss: 1007.4674\n",
      "Epoch 90/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1080.6368 - val_loss: 1004.6415\n",
      "Epoch 91/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1044.4796 - val_loss: 1001.2124\n",
      "Epoch 92/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1054.8032 - val_loss: 989.8169\n",
      "Epoch 93/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1058.7237 - val_loss: 1000.1918\n",
      "Epoch 94/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1034.0709 - val_loss: 995.0778\n",
      "Epoch 95/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1048.1416 - val_loss: 997.3460\n",
      "Epoch 96/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 1076.4671 - val_loss: 998.1074\n",
      "Epoch 97/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1011.5083 - val_loss: 992.0611\n",
      "Epoch 98/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1055.6994 - val_loss: 1013.3093\n",
      "Epoch 99/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 995.9686 - val_loss: 1023.7041\n",
      "Epoch 100/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1031.8294 - val_loss: 1031.4459\n",
      "Epoch 101/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1090.7073 - val_loss: 1031.2582\n",
      "Epoch 102/500\n",
      "720/720 [==============================] - 0s 127us/step - loss: 993.5509 - val_loss: 1031.2876\n",
      "Epoch 103/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1035.7983 - val_loss: 1034.3031\n",
      "Epoch 104/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1045.7340 - val_loss: 1036.7287\n",
      "Epoch 105/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1094.2819 - val_loss: 1023.9110\n",
      "Epoch 106/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1095.7469 - val_loss: 1027.1732\n",
      "Epoch 107/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1016.9044 - val_loss: 1029.5166\n",
      "Epoch 108/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1047.1667 - val_loss: 1050.3407\n",
      "Epoch 109/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1080.7686 - val_loss: 1037.9493\n",
      "Epoch 110/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1035.6991 - val_loss: 1042.2742\n",
      "Epoch 111/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1025.2349 - val_loss: 1046.9402\n",
      "Epoch 112/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 996.8608 - val_loss: 1038.7732\n",
      "Epoch 113/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1045.8535 - val_loss: 1031.2649\n",
      "Epoch 114/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1006.1264 - val_loss: 1034.1773\n",
      "Epoch 115/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1056.9362 - val_loss: 1024.8739\n",
      "Epoch 116/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1038.1527 - val_loss: 1005.8098\n",
      "Epoch 117/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1025.4842 - val_loss: 1007.4908\n",
      "Epoch 118/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 988.7856 - val_loss: 1036.3251\n",
      "Epoch 119/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 994.6122 - val_loss: 1038.1799\n",
      "Epoch 120/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 989.6423 - val_loss: 1041.2788\n",
      "Epoch 121/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1092.8561 - val_loss: 1026.0998\n",
      "Epoch 122/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1010.6679 - val_loss: 1024.5617\n",
      "Epoch 123/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 974.1589 - val_loss: 1032.7397\n",
      "Epoch 124/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 989.8643 - val_loss: 1050.7793\n",
      "Epoch 125/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1040.8132 - val_loss: 1035.6568\n",
      "Epoch 126/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 984.9218 - val_loss: 1030.9423\n",
      "Epoch 127/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 978.6178 - val_loss: 1037.0372\n",
      "Epoch 128/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1026.1730 - val_loss: 1035.6548\n",
      "Epoch 129/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 995.6718 - val_loss: 1052.9353\n",
      "Epoch 130/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 969.7812 - val_loss: 1073.7619\n",
      "Epoch 131/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1013.7418 - val_loss: 1062.9782\n",
      "Epoch 132/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 1017.0959 - val_loss: 1056.5510\n",
      "Epoch 133/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1031.3503 - val_loss: 1062.8260\n",
      "Epoch 134/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 981.7645 - val_loss: 1059.7897\n",
      "Epoch 135/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 985.0133 - val_loss: 1045.3242\n",
      "Epoch 136/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 951.5426 - val_loss: 1037.5804\n",
      "Epoch 137/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1039.7352 - val_loss: 1027.7909\n",
      "Epoch 138/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 973.6509 - val_loss: 1012.6532\n",
      "Epoch 139/500\n",
      "720/720 [==============================] - 0s 128us/step - loss: 966.4252 - val_loss: 1032.7432\n",
      "Epoch 140/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 981.6549 - val_loss: 1043.5661\n",
      "Epoch 141/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1025.8724 - val_loss: 1041.7913\n",
      "Epoch 142/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1001.1936 - val_loss: 1035.7431\n",
      "Epoch 143/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 948.6779 - val_loss: 1023.6670\n",
      "Epoch 144/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 981.2309 - val_loss: 1015.5510\n",
      "Epoch 145/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 990.4794 - val_loss: 1004.3147\n",
      "Epoch 146/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 972.4166 - val_loss: 1003.1196\n",
      "Epoch 147/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1069.6957 - val_loss: 1010.2785\n",
      "Epoch 148/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 967.7311 - val_loss: 1034.7552\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 116us/step - loss: 974.2195 - val_loss: 1034.3611\n",
      "Epoch 150/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 935.0279 - val_loss: 1018.2993\n",
      "Epoch 151/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 923.5620 - val_loss: 1001.8334\n",
      "Epoch 152/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 956.5206 - val_loss: 991.0175\n",
      "Epoch 153/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1008.3703 - val_loss: 999.4804\n",
      "Epoch 154/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 1003.4433 - val_loss: 981.1553\n",
      "Epoch 155/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 974.5710 - val_loss: 980.6495\n",
      "Epoch 156/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 1024.0394 - val_loss: 985.6144\n",
      "Epoch 157/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 923.0769 - val_loss: 987.0828\n",
      "Epoch 158/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 946.4326 - val_loss: 997.5628\n",
      "Epoch 159/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 990.0988 - val_loss: 993.2291\n",
      "Epoch 160/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 987.5500 - val_loss: 995.5055\n",
      "Epoch 161/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1001.3063 - val_loss: 992.3134\n",
      "Epoch 162/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1017.0391 - val_loss: 996.4688\n",
      "Epoch 163/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 1010.4835 - val_loss: 998.3501\n",
      "Epoch 164/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 985.2672 - val_loss: 1007.9093\n",
      "Epoch 165/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 965.6071 - val_loss: 1004.1157\n",
      "Epoch 166/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 961.0329 - val_loss: 1012.3691\n",
      "Epoch 167/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 950.2838 - val_loss: 1015.3190\n",
      "Epoch 168/500\n",
      "720/720 [==============================] - 0s 127us/step - loss: 933.5687 - val_loss: 1023.8964\n",
      "Epoch 169/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 948.5381 - val_loss: 1013.3911\n",
      "Epoch 170/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1020.1047 - val_loss: 1013.0094\n",
      "Epoch 171/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 964.8761 - val_loss: 1022.3747\n",
      "Epoch 172/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 934.3145 - val_loss: 1028.3191\n",
      "Epoch 173/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 935.5229 - val_loss: 1028.3582\n",
      "Epoch 174/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 933.1903 - val_loss: 1029.4104\n",
      "Epoch 175/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 995.7429 - val_loss: 1025.8289\n",
      "Epoch 176/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 955.8845 - val_loss: 1027.0313\n",
      "Epoch 177/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 979.3684 - val_loss: 1036.6868\n",
      "Epoch 178/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 910.8081 - val_loss: 1021.4075\n",
      "Epoch 179/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 987.4161 - val_loss: 1045.5201\n",
      "Epoch 180/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 954.2123 - val_loss: 1026.1066\n",
      "Epoch 181/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 952.0875 - val_loss: 1030.3767\n",
      "Epoch 182/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 943.1251 - val_loss: 1041.1001\n",
      "Epoch 183/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 992.8036 - val_loss: 1040.2437\n",
      "Epoch 184/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 969.7626 - val_loss: 1037.9818\n",
      "Epoch 185/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 943.2094 - val_loss: 1037.8601\n",
      "Epoch 186/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 944.6737 - val_loss: 1045.0174\n",
      "Epoch 187/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 963.6311 - val_loss: 1036.1317\n",
      "Epoch 188/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 978.1978 - val_loss: 1056.6371\n",
      "Epoch 189/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 969.0434 - val_loss: 1042.0556\n",
      "Epoch 190/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 979.5090 - val_loss: 1056.6659\n",
      "Epoch 191/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 956.7826 - val_loss: 1047.2466\n",
      "Epoch 192/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 975.3767 - val_loss: 1040.7969\n",
      "Epoch 193/500\n",
      "720/720 [==============================] - 0s 127us/step - loss: 1000.4266 - val_loss: 1042.4660\n",
      "Epoch 194/500\n",
      "720/720 [==============================] - 0s 126us/step - loss: 977.3727 - val_loss: 1043.4807\n",
      "Epoch 195/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 930.7043 - val_loss: 1021.9266\n",
      "Epoch 196/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 959.2753 - val_loss: 1018.4293\n",
      "Epoch 197/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 941.8564 - val_loss: 1014.5205\n",
      "Epoch 198/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 971.0148 - val_loss: 1011.5081\n",
      "Epoch 199/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 980.6769 - val_loss: 1022.6988\n",
      "Epoch 200/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 910.2588 - val_loss: 1025.9170\n",
      "Epoch 201/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 916.3100 - val_loss: 1019.9559\n",
      "Epoch 202/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 958.4701 - val_loss: 1041.4221\n",
      "Epoch 203/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 936.8313 - val_loss: 1040.5981\n",
      "Epoch 204/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 924.8259 - val_loss: 1023.1706\n",
      "Epoch 205/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 987.1268 - val_loss: 1008.2217\n",
      "Epoch 206/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 921.6710 - val_loss: 1025.2964\n",
      "Epoch 207/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 887.8543 - val_loss: 1012.2273\n",
      "Epoch 208/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 939.1228 - val_loss: 986.3921\n",
      "Epoch 209/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 976.0862 - val_loss: 980.8655\n",
      "Epoch 210/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 915.9658 - val_loss: 985.5053\n",
      "Epoch 211/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 927.2633 - val_loss: 988.0684\n",
      "Epoch 212/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 902.8279 - val_loss: 986.1510\n",
      "Epoch 213/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 869.1284 - val_loss: 1031.1410\n",
      "Epoch 214/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1052.4079 - val_loss: 1036.3467\n",
      "Epoch 215/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 931.6569 - val_loss: 1032.1004\n",
      "Epoch 216/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 970.3222 - val_loss: 1017.5020\n",
      "Epoch 217/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 944.1014 - val_loss: 1026.9320\n",
      "Epoch 218/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 967.8599 - val_loss: 1024.8257\n",
      "Epoch 219/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 892.9831 - val_loss: 1018.2800\n",
      "Epoch 220/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 954.1294 - val_loss: 1035.6403\n",
      "Epoch 221/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 953.1302 - val_loss: 1063.1318\n",
      "Epoch 222/500\n",
      "720/720 [==============================] - ETA: 0s - loss: 872.4418 - 0s 119us/step - loss: 902.8036 - val_loss: 1053.8531\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 114us/step - loss: 893.3231 - val_loss: 1021.1344\n",
      "Epoch 224/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 893.1045 - val_loss: 1010.0576\n",
      "Epoch 225/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 885.7538 - val_loss: 1023.1441\n",
      "Epoch 226/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 909.0845 - val_loss: 1019.7083\n",
      "Epoch 227/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 918.5704 - val_loss: 997.6454\n",
      "Epoch 228/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 926.9376 - val_loss: 984.5007\n",
      "Epoch 229/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 927.0373 - val_loss: 1002.3656\n",
      "Epoch 230/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 1041.3949 - val_loss: 1021.3062\n",
      "Epoch 231/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 984.5321 - val_loss: 1025.5694\n",
      "Epoch 232/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 894.1186 - val_loss: 1003.8229\n",
      "Epoch 233/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 974.5935 - val_loss: 995.1666\n",
      "Epoch 234/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 916.9316 - val_loss: 988.4842\n",
      "Epoch 235/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 898.3480 - val_loss: 983.0179\n",
      "Epoch 236/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 946.5282 - val_loss: 981.6556\n",
      "Epoch 237/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 925.9884 - val_loss: 992.8932\n",
      "Epoch 238/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 881.1808 - val_loss: 1002.2381\n",
      "Epoch 239/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 935.8633 - val_loss: 1016.9323\n",
      "Epoch 240/500\n",
      "720/720 [==============================] - 0s 131us/step - loss: 896.2845 - val_loss: 1017.8383\n",
      "Epoch 241/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 875.5258 - val_loss: 1025.2083\n",
      "Epoch 242/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 935.2820 - val_loss: 1042.9838\n",
      "Epoch 243/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 914.1178 - val_loss: 1051.1511\n",
      "Epoch 244/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 920.6271 - val_loss: 1055.4682\n",
      "Epoch 245/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 935.7453 - val_loss: 1050.4549\n",
      "Epoch 246/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 945.4196 - val_loss: 1039.1735\n",
      "Epoch 247/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 946.8797 - val_loss: 1051.3273\n",
      "Epoch 248/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 891.4664 - val_loss: 1061.8731\n",
      "Epoch 249/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 923.8020 - val_loss: 1063.8292\n",
      "Epoch 250/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 950.6276 - val_loss: 1059.2044\n",
      "Epoch 251/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 908.3369 - val_loss: 1060.0134\n",
      "Epoch 252/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 909.9146 - val_loss: 1052.9987\n",
      "Epoch 253/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 927.2177 - val_loss: 1043.5151\n",
      "Epoch 254/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 960.2166 - val_loss: 1033.6685\n",
      "Epoch 255/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 906.9396 - val_loss: 1031.7048\n",
      "Epoch 256/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 887.4931 - val_loss: 1026.4772\n",
      "Epoch 257/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 952.7504 - val_loss: 1045.0494\n",
      "Epoch 258/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 926.2767 - val_loss: 1063.8269\n",
      "Epoch 259/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 950.3278 - val_loss: 1049.3118\n",
      "Epoch 260/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 913.4992 - val_loss: 1053.5940\n",
      "Epoch 261/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 913.7653 - val_loss: 1066.9484\n",
      "Epoch 262/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 974.9184 - val_loss: 1069.8477\n",
      "Epoch 263/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 891.2995 - val_loss: 1061.2719\n",
      "Epoch 264/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 923.9422 - val_loss: 1053.7017\n",
      "Epoch 265/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 924.1839 - val_loss: 1060.1326\n",
      "Epoch 266/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 915.6127 - val_loss: 1050.9110\n",
      "Epoch 267/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 858.2524 - val_loss: 1043.1082\n",
      "Epoch 268/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 949.3737 - val_loss: 1051.0872\n",
      "Epoch 269/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 913.8196 - val_loss: 1048.4625\n",
      "Epoch 270/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 903.1237 - val_loss: 1041.2248\n",
      "Epoch 271/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 911.8281 - val_loss: 1034.9239\n",
      "Epoch 272/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 892.6838 - val_loss: 1048.7892\n",
      "Epoch 273/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 899.7514 - val_loss: 1061.2165\n",
      "Epoch 274/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 886.8679 - val_loss: 1052.3968\n",
      "Epoch 275/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 879.4830 - val_loss: 1047.6526\n",
      "Epoch 276/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 932.6120 - val_loss: 1050.7760\n",
      "Epoch 277/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 932.2901 - val_loss: 1034.8962\n",
      "Epoch 278/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 990.3860 - val_loss: 1049.5274\n",
      "Epoch 279/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 975.6851 - val_loss: 1052.5423\n",
      "Epoch 280/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 990.6813 - val_loss: 1079.2888\n",
      "Epoch 281/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 959.5673 - val_loss: 1078.7258\n",
      "Epoch 282/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 853.9185 - val_loss: 1068.4179\n",
      "Epoch 283/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 918.9360 - val_loss: 1074.4165\n",
      "Epoch 284/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 945.4389 - val_loss: 1071.3991\n",
      "Epoch 285/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 949.7755 - val_loss: 1070.4094\n",
      "Epoch 286/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 952.7912 - val_loss: 1078.3819\n",
      "Epoch 287/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 916.3862 - val_loss: 1084.6609\n",
      "Epoch 288/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 969.4619 - val_loss: 1079.3566\n",
      "Epoch 289/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 914.7799 - val_loss: 1064.6949\n",
      "Epoch 290/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 904.7504 - val_loss: 1079.4508\n",
      "Epoch 291/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 891.0871 - val_loss: 1077.6495\n",
      "Epoch 292/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 950.5447 - val_loss: 1063.7179\n",
      "Epoch 293/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 870.0791 - val_loss: 1054.6204\n",
      "Epoch 294/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 920.9889 - val_loss: 1056.1845\n",
      "Epoch 295/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 891.1951 - val_loss: 1063.3500\n",
      "Epoch 296/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 873.2047 - val_loss: 1047.7255\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 111us/step - loss: 867.4250 - val_loss: 1032.8038\n",
      "Epoch 298/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 901.3120 - val_loss: 1030.1269\n",
      "Epoch 299/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 899.7568 - val_loss: 1025.3894\n",
      "Epoch 300/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 921.7162 - val_loss: 1025.9754\n",
      "Epoch 301/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 928.8061 - val_loss: 1023.0035\n",
      "Epoch 302/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 934.5324 - val_loss: 1040.7820\n",
      "Epoch 303/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 946.0813 - val_loss: 1042.8491\n",
      "Epoch 304/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 848.0939 - val_loss: 1028.1367\n",
      "Epoch 305/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 948.1358 - val_loss: 1032.8064\n",
      "Epoch 306/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 853.5377 - val_loss: 1022.6681\n",
      "Epoch 307/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 871.0669 - val_loss: 1016.3141\n",
      "Epoch 308/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 842.0212 - val_loss: 1011.3108\n",
      "Epoch 309/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 913.6176 - val_loss: 1018.1362\n",
      "Epoch 310/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 913.1029 - val_loss: 1015.5621\n",
      "Epoch 311/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 862.2982 - val_loss: 1031.1013\n",
      "Epoch 312/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 888.1685 - val_loss: 1026.3107\n",
      "Epoch 313/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 926.5394 - val_loss: 1028.2045\n",
      "Epoch 314/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 915.6819 - val_loss: 1012.2312\n",
      "Epoch 315/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 948.5858 - val_loss: 1001.1317\n",
      "Epoch 316/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 916.8079 - val_loss: 996.7346\n",
      "Epoch 317/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 847.2276 - val_loss: 1009.5015\n",
      "Epoch 318/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 915.8203 - val_loss: 1007.1746\n",
      "Epoch 319/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 882.0578 - val_loss: 1022.6525\n",
      "Epoch 320/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 921.8188 - val_loss: 1037.4912\n",
      "Epoch 321/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 905.8711 - val_loss: 1045.7283\n",
      "Epoch 322/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 906.1378 - val_loss: 1035.9883\n",
      "Epoch 323/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 917.0741 - val_loss: 1019.4419\n",
      "Epoch 324/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 871.0708 - val_loss: 1017.1830\n",
      "Epoch 325/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 863.9557 - val_loss: 1032.6495\n",
      "Epoch 326/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 820.0170 - val_loss: 1039.8477\n",
      "Epoch 327/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 846.6693 - val_loss: 1032.6182\n",
      "Epoch 328/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 905.0689 - val_loss: 1032.0112\n",
      "Epoch 329/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 941.3001 - val_loss: 1034.6086\n",
      "Epoch 330/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 897.2324 - val_loss: 1023.1799\n",
      "Epoch 331/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 895.6440 - val_loss: 1020.0272\n",
      "Epoch 332/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 901.0206 - val_loss: 1024.6384\n",
      "Epoch 333/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 940.5165 - val_loss: 1014.5509\n",
      "Epoch 334/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 816.2280 - val_loss: 1015.3620\n",
      "Epoch 335/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 908.5761 - val_loss: 1014.3336\n",
      "Epoch 336/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 915.9847 - val_loss: 1015.9782\n",
      "Epoch 337/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 897.4614 - val_loss: 1014.2597\n",
      "Epoch 338/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 863.8606 - val_loss: 1040.5298\n",
      "Epoch 339/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 945.1414 - val_loss: 1004.6094\n",
      "Epoch 340/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 871.2706 - val_loss: 1014.9128\n",
      "Epoch 341/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 857.0136 - val_loss: 1019.3010\n",
      "Epoch 342/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 833.3016 - val_loss: 1014.7297\n",
      "Epoch 343/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 881.0208 - val_loss: 1015.4393\n",
      "Epoch 344/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 918.4909 - val_loss: 1003.1066\n",
      "Epoch 345/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 854.3396 - val_loss: 995.3642\n",
      "Epoch 346/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 870.6396 - val_loss: 1012.1941\n",
      "Epoch 347/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 897.9612 - val_loss: 1006.7941\n",
      "Epoch 348/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 922.8129 - val_loss: 1033.5242\n",
      "Epoch 349/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 859.5615 - val_loss: 1038.0527\n",
      "Epoch 350/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 867.4244 - val_loss: 1047.3380\n",
      "Epoch 351/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 922.6180 - val_loss: 1029.3638\n",
      "Epoch 352/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 947.6925 - val_loss: 1034.3234\n",
      "Epoch 353/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 898.5255 - val_loss: 1041.1629\n",
      "Epoch 354/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 922.2338 - val_loss: 1035.4854\n",
      "Epoch 355/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 884.5954 - val_loss: 1056.0492\n",
      "Epoch 356/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 817.3840 - val_loss: 1059.8749\n",
      "Epoch 357/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 868.5243 - val_loss: 1060.9889\n",
      "Epoch 358/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 882.4941 - val_loss: 1047.8996\n",
      "Epoch 359/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 845.6883 - val_loss: 1046.7634\n",
      "Epoch 360/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 875.6659 - val_loss: 1039.4514\n",
      "Epoch 361/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 850.2460 - val_loss: 1021.8573\n",
      "Epoch 362/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 914.3317 - val_loss: 1019.4162\n",
      "Epoch 363/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 838.1111 - val_loss: 1035.2407\n",
      "Epoch 364/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 935.6634 - val_loss: 1058.4372\n",
      "Epoch 365/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 906.8391 - val_loss: 1050.4572\n",
      "Epoch 366/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 927.5752 - val_loss: 1045.3869\n",
      "Epoch 367/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 913.3336 - val_loss: 1038.9130\n",
      "Epoch 368/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 855.3718 - val_loss: 1033.4673\n",
      "Epoch 369/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 915.4801 - val_loss: 1052.4126\n",
      "Epoch 370/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 868.9847 - val_loss: 1034.6347\n",
      "Epoch 371/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 113us/step - loss: 874.0229 - val_loss: 1033.1619\n",
      "Epoch 372/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 891.8764 - val_loss: 1058.7830\n",
      "Epoch 373/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 820.9445 - val_loss: 1048.8377\n",
      "Epoch 374/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 896.3727 - val_loss: 1055.9154\n",
      "Epoch 375/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 887.7904 - val_loss: 1057.5291\n",
      "Epoch 376/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 880.2049 - val_loss: 1042.4956\n",
      "Epoch 377/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 893.1005 - val_loss: 1042.6265\n",
      "Epoch 378/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 863.5121 - val_loss: 1032.3759\n",
      "Epoch 379/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 884.3000 - val_loss: 1033.0374\n",
      "Epoch 380/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 837.5827 - val_loss: 1017.0369\n",
      "Epoch 381/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 871.6831 - val_loss: 1027.9017\n",
      "Epoch 382/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 870.0071 - val_loss: 1045.8681\n",
      "Epoch 383/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 862.8269 - val_loss: 1048.4890\n",
      "Epoch 384/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 918.8905 - val_loss: 1041.3109\n",
      "Epoch 385/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 875.4428 - val_loss: 1027.2479\n",
      "Epoch 386/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 864.8517 - val_loss: 1040.8857\n",
      "Epoch 387/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 860.5189 - val_loss: 1064.8514\n",
      "Epoch 388/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 880.6055 - val_loss: 1070.1473\n",
      "Epoch 389/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 959.8174 - val_loss: 1067.8924\n",
      "Epoch 390/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 839.9799 - val_loss: 1071.4850\n",
      "Epoch 391/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 964.1569 - val_loss: 1056.1829\n",
      "Epoch 392/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 854.2907 - val_loss: 1052.7382\n",
      "Epoch 393/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 902.5936 - val_loss: 1051.5348\n",
      "Epoch 394/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 943.9969 - val_loss: 1046.6811\n",
      "Epoch 395/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 907.0290 - val_loss: 1049.1272\n",
      "Epoch 396/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 888.6995 - val_loss: 1059.2227\n",
      "Epoch 397/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 841.6887 - val_loss: 1052.7413\n",
      "Epoch 398/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 899.8535 - val_loss: 1057.5459\n",
      "Epoch 399/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 883.8316 - val_loss: 1069.1890\n",
      "Epoch 400/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 873.5446 - val_loss: 1062.9304\n",
      "Epoch 401/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 872.1428 - val_loss: 1064.2010\n",
      "Epoch 402/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 838.9453 - val_loss: 1064.0991\n",
      "Epoch 403/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 884.7191 - val_loss: 1072.0735\n",
      "Epoch 404/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 892.0547 - val_loss: 1079.5690\n",
      "Epoch 405/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 886.8531 - val_loss: 1066.4340\n",
      "Epoch 406/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 877.1231 - val_loss: 1062.3154\n",
      "Epoch 407/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 932.7686 - val_loss: 1074.5488\n",
      "Epoch 408/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 832.7291 - val_loss: 1070.7833\n",
      "Epoch 409/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 925.3210 - val_loss: 1066.7192\n",
      "Epoch 410/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 862.2184 - val_loss: 1070.0861\n",
      "Epoch 411/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 816.6339 - val_loss: 1059.1437\n",
      "Epoch 412/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 856.8982 - val_loss: 1062.3817\n",
      "Epoch 413/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 899.2212 - val_loss: 1070.8895\n",
      "Epoch 414/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 866.7072 - val_loss: 1076.8093\n",
      "Epoch 415/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 870.7487 - val_loss: 1065.4175\n",
      "Epoch 416/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 928.7055 - val_loss: 1070.1934\n",
      "Epoch 417/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 885.5485 - val_loss: 1058.6244\n",
      "Epoch 418/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 885.5514 - val_loss: 1053.3534\n",
      "Epoch 419/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 829.3089 - val_loss: 1042.3707\n",
      "Epoch 420/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 869.1857 - val_loss: 1037.9389\n",
      "Epoch 421/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 877.7032 - val_loss: 1051.1700\n",
      "Epoch 422/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 856.1868 - val_loss: 1059.1282\n",
      "Epoch 423/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 876.8586 - val_loss: 1052.6027\n",
      "Epoch 424/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 799.7125 - val_loss: 1052.1443\n",
      "Epoch 425/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 935.1844 - val_loss: 1040.4741\n",
      "Epoch 426/500\n",
      "720/720 [==============================] - 0s 105us/step - loss: 883.4313 - val_loss: 1065.0982\n",
      "Epoch 427/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 875.4149 - val_loss: 1071.3782\n",
      "Epoch 428/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 858.2536 - val_loss: 1071.9289\n",
      "Epoch 429/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 889.6955 - val_loss: 1077.6411\n",
      "Epoch 430/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 862.6530 - val_loss: 1077.6746\n",
      "Epoch 431/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 874.9041 - val_loss: 1078.9140\n",
      "Epoch 432/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 868.4207 - val_loss: 1078.3764\n",
      "Epoch 433/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 862.3361 - val_loss: 1074.3435\n",
      "Epoch 434/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 879.3849 - val_loss: 1068.1320\n",
      "Epoch 435/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 852.5149 - val_loss: 1063.2514\n",
      "Epoch 436/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 884.7757 - val_loss: 1071.8439\n",
      "Epoch 437/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 868.0169 - val_loss: 1069.3509\n",
      "Epoch 438/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 815.9314 - val_loss: 1069.0300\n",
      "Epoch 439/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 901.2001 - val_loss: 1068.8467\n",
      "Epoch 440/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 908.1859 - val_loss: 1063.7872\n",
      "Epoch 441/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 847.2989 - val_loss: 1056.5002\n",
      "Epoch 442/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 835.8562 - val_loss: 1046.4868\n",
      "Epoch 443/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 868.1604 - val_loss: 1039.4788\n",
      "Epoch 444/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 821.7785 - val_loss: 1048.2095\n",
      "Epoch 445/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 114us/step - loss: 906.7826 - val_loss: 1044.7264\n",
      "Epoch 446/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 907.9975 - val_loss: 1039.3114\n",
      "Epoch 447/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 845.3116 - val_loss: 1050.2159\n",
      "Epoch 448/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 887.7892 - val_loss: 1048.5457\n",
      "Epoch 449/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 852.0319 - val_loss: 1058.0608\n",
      "Epoch 450/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 859.8232 - val_loss: 1053.9151\n",
      "Epoch 451/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 840.0410 - val_loss: 1067.7586\n",
      "Epoch 452/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 907.0897 - val_loss: 1066.7836\n",
      "Epoch 453/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 882.5768 - val_loss: 1063.9796\n",
      "Epoch 454/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 822.3143 - val_loss: 1084.9106\n",
      "Epoch 455/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 899.4205 - val_loss: 1086.8460\n",
      "Epoch 456/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 862.7330 - val_loss: 1074.5892\n",
      "Epoch 457/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 861.0533 - val_loss: 1078.9583\n",
      "Epoch 458/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 843.4202 - val_loss: 1070.0291\n",
      "Epoch 459/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 895.4471 - val_loss: 1074.7299\n",
      "Epoch 460/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 885.9824 - val_loss: 1056.4238\n",
      "Epoch 461/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 829.6815 - val_loss: 1057.7240\n",
      "Epoch 462/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 857.6285 - val_loss: 1064.6177\n",
      "Epoch 463/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 848.4773 - val_loss: 1059.7797\n",
      "Epoch 464/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 954.8147 - val_loss: 1062.4753\n",
      "Epoch 465/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 856.7197 - val_loss: 1060.0232\n",
      "Epoch 466/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 825.5080 - val_loss: 1060.6677\n",
      "Epoch 467/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 860.0578 - val_loss: 1057.4669\n",
      "Epoch 468/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 892.7178 - val_loss: 1062.3173\n",
      "Epoch 469/500\n",
      "720/720 [==============================] - 0s 104us/step - loss: 950.6462 - val_loss: 1068.6533\n",
      "Epoch 470/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 826.8932 - val_loss: 1077.8493\n",
      "Epoch 471/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 865.8662 - val_loss: 1083.5427\n",
      "Epoch 472/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 862.2622 - val_loss: 1081.5770\n",
      "Epoch 473/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 849.6464 - val_loss: 1074.7261\n",
      "Epoch 474/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 793.1401 - val_loss: 1099.1410\n",
      "Epoch 475/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 866.0012 - val_loss: 1111.7935\n",
      "Epoch 476/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 883.1892 - val_loss: 1108.7682\n",
      "Epoch 477/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 895.9517 - val_loss: 1118.4566\n",
      "Epoch 478/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 874.3278 - val_loss: 1118.1821\n",
      "Epoch 479/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 853.5634 - val_loss: 1118.8529\n",
      "Epoch 480/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 789.8501 - val_loss: 1116.7916\n",
      "Epoch 481/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 887.8982 - val_loss: 1111.2859\n",
      "Epoch 482/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 873.7538 - val_loss: 1120.7601\n",
      "Epoch 483/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 910.9893 - val_loss: 1111.5831\n",
      "Epoch 484/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 872.2484 - val_loss: 1119.1506\n",
      "Epoch 485/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 819.8279 - val_loss: 1117.8205\n",
      "Epoch 486/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 835.3343 - val_loss: 1110.9191\n",
      "Epoch 487/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 899.2146 - val_loss: 1093.8376\n",
      "Epoch 488/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 877.3559 - val_loss: 1083.0842\n",
      "Epoch 489/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 854.1995 - val_loss: 1082.8635\n",
      "Epoch 490/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 865.0923 - val_loss: 1075.6990\n",
      "Epoch 491/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 842.8855 - val_loss: 1075.2563\n",
      "Epoch 492/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 819.5306 - val_loss: 1084.1987\n",
      "Epoch 493/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 842.7421 - val_loss: 1076.7570\n",
      "Epoch 494/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 811.6857 - val_loss: 1075.3620\n",
      "Epoch 495/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 786.7759 - val_loss: 1089.8399\n",
      "Epoch 496/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 888.0110 - val_loss: 1098.7648\n",
      "Epoch 497/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 885.0106 - val_loss: 1100.9751\n",
      "Epoch 498/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 874.7962 - val_loss: 1099.4250\n",
      "Epoch 499/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 890.8513 - val_loss: 1116.2044\n",
      "Epoch 500/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 842.6731 - val_loss: 1119.4180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f48355cf8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, verbose =1, validation_data=(X_valid, y_valid), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 60)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca= PCA()\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_valid_pca = pca.transform(X_valid)\n",
    "\n",
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forests:\n",
      "\n",
      "2128.4854632461083\n",
      "For SVC:\n",
      "\n",
      "3057.5577232922146\n",
      "For KNN:\n",
      "\n",
      "2972.052348041669\n",
      "For Adaboost:\n",
      "\n",
      "2382.410669449239\n",
      "For Gradient Boosting:\n",
      "\n",
      "2079.8631594954923\n",
      "For XG Boosting:\n",
      "\n",
      "2086.731932366649\n"
     ]
    }
   ],
   "source": [
    "classifier_list = try_default_classifiers(X_train_pca, y_train, X_valid_pca , y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "#model.add(Lambda(lambda x: x , input_shape = (24)))\n",
    "#model.add(Lambda(lambda x: x+0.1 , input_shape = (64,64,3)))\n",
    "#model.add(Flatten())\n",
    "model_2.add(BatchNormalization(input_shape=(60,)))\n",
    "model_2.add(Dense(300))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dense(150))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dense(75))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(1))\n",
    "model_2.add(Activation('linear'))\n",
    "model_2.compile(optimizer = 'Adam' , loss = root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/500\n",
      "720/720 [==============================] - 0s 497us/step - loss: 3223.9308 - val_loss: 2881.4986\n",
      "Epoch 2/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 3222.4791 - val_loss: 2880.3368\n",
      "Epoch 3/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 3220.6607 - val_loss: 2878.6110\n",
      "Epoch 4/500\n",
      "720/720 [==============================] - 0s 138us/step - loss: 3217.8449 - val_loss: 2875.6449\n",
      "Epoch 5/500\n",
      "720/720 [==============================] - 0s 131us/step - loss: 3213.6426 - val_loss: 2870.1692\n",
      "Epoch 6/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 3205.2851 - val_loss: 2858.8173\n",
      "Epoch 7/500\n",
      "720/720 [==============================] - 0s 127us/step - loss: 3185.4650 - val_loss: 2827.2270\n",
      "Epoch 8/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 3132.7670 - val_loss: 2727.1722\n",
      "Epoch 9/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 3035.5974 - val_loss: 2564.7952\n",
      "Epoch 10/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 2891.0152 - val_loss: 2361.9101\n",
      "Epoch 11/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 2712.5373 - val_loss: 2134.9969\n",
      "Epoch 12/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 2493.0251 - val_loss: 1963.9258\n",
      "Epoch 13/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 2289.7677 - val_loss: 1734.8719\n",
      "Epoch 14/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 2056.0940 - val_loss: 1595.7826\n",
      "Epoch 15/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1844.3697 - val_loss: 1535.7726\n",
      "Epoch 16/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1654.1137 - val_loss: 1425.0757\n",
      "Epoch 17/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1532.0599 - val_loss: 1350.5957\n",
      "Epoch 18/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 1452.5418 - val_loss: 1293.1709\n",
      "Epoch 19/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 1422.4090 - val_loss: 1249.6885\n",
      "Epoch 20/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1395.6103 - val_loss: 1186.4269\n",
      "Epoch 21/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1369.2110 - val_loss: 1154.4130\n",
      "Epoch 22/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1313.0227 - val_loss: 1135.9566\n",
      "Epoch 23/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1291.7964 - val_loss: 1155.2057\n",
      "Epoch 24/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1275.8979 - val_loss: 1171.6766\n",
      "Epoch 25/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1246.2583 - val_loss: 1193.5859\n",
      "Epoch 26/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1213.6379 - val_loss: 1156.6036\n",
      "Epoch 27/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1266.8664 - val_loss: 1157.0042\n",
      "Epoch 28/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1161.0178 - val_loss: 1169.7397\n",
      "Epoch 29/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1203.4923 - val_loss: 1172.1258\n",
      "Epoch 30/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1170.8624 - val_loss: 1162.1322\n",
      "Epoch 31/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1128.2541 - val_loss: 1164.1954\n",
      "Epoch 32/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1145.1539 - val_loss: 1155.2789\n",
      "Epoch 33/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1139.3538 - val_loss: 1164.8766\n",
      "Epoch 34/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1093.3272 - val_loss: 1178.3201\n",
      "Epoch 35/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1215.4530 - val_loss: 1194.3522\n",
      "Epoch 36/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1115.8124 - val_loss: 1222.3237\n",
      "Epoch 37/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1066.8771 - val_loss: 1196.3555\n",
      "Epoch 38/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1133.3675 - val_loss: 1206.6948\n",
      "Epoch 39/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1079.6077 - val_loss: 1196.9243\n",
      "Epoch 40/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 1126.6982 - val_loss: 1193.0610\n",
      "Epoch 41/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1036.2905 - val_loss: 1193.4599\n",
      "Epoch 42/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1068.5202 - val_loss: 1181.1584\n",
      "Epoch 43/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1062.1099 - val_loss: 1177.0849\n",
      "Epoch 44/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1066.3366 - val_loss: 1186.4758\n",
      "Epoch 45/500\n",
      "720/720 [==============================] - 0s 127us/step - loss: 1088.4639 - val_loss: 1182.0066\n",
      "Epoch 46/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1116.6324 - val_loss: 1184.3581\n",
      "Epoch 47/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1030.1906 - val_loss: 1190.6076\n",
      "Epoch 48/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1026.6489 - val_loss: 1200.4545\n",
      "Epoch 49/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1049.0734 - val_loss: 1207.7268\n",
      "Epoch 50/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1076.5589 - val_loss: 1200.1067\n",
      "Epoch 51/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 1023.0681 - val_loss: 1190.3641\n",
      "Epoch 52/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1046.4274 - val_loss: 1184.1530\n",
      "Epoch 53/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1070.6920 - val_loss: 1192.9713\n",
      "Epoch 54/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 1033.9598 - val_loss: 1207.9021\n",
      "Epoch 55/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 977.1338 - val_loss: 1216.7288\n",
      "Epoch 56/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1002.2001 - val_loss: 1170.4083\n",
      "Epoch 57/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1017.6170 - val_loss: 1169.5243\n",
      "Epoch 58/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1007.4852 - val_loss: 1182.9975\n",
      "Epoch 59/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1001.7409 - val_loss: 1190.7741\n",
      "Epoch 60/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 1017.5317 - val_loss: 1180.8384\n",
      "Epoch 61/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 1014.6067 - val_loss: 1176.8312\n",
      "Epoch 62/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 994.7427 - val_loss: 1168.5197\n",
      "Epoch 63/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 1001.4485 - val_loss: 1153.1008\n",
      "Epoch 64/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 1028.0486 - val_loss: 1154.5011\n",
      "Epoch 65/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 1008.0949 - val_loss: 1156.1920\n",
      "Epoch 66/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 937.2838 - val_loss: 1157.8177\n",
      "Epoch 67/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 934.5796 - val_loss: 1166.9492\n",
      "Epoch 68/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 982.0279 - val_loss: 1160.8478\n",
      "Epoch 69/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 1021.4747 - val_loss: 1186.5699\n",
      "Epoch 70/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 962.8820 - val_loss: 1189.4687\n",
      "Epoch 71/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 976.0437 - val_loss: 1174.2663\n",
      "Epoch 72/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 993.4370 - val_loss: 1183.1795\n",
      "Epoch 73/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 1006.8580 - val_loss: 1186.9781\n",
      "Epoch 74/500\n",
      "720/720 [==============================] - 0s 126us/step - loss: 995.6649 - val_loss: 1204.1983\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 111us/step - loss: 1000.4319 - val_loss: 1214.0425\n",
      "Epoch 76/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 973.7259 - val_loss: 1212.5852\n",
      "Epoch 77/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 1006.1501 - val_loss: 1210.4939\n",
      "Epoch 78/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 925.3837 - val_loss: 1220.8603\n",
      "Epoch 79/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 913.7905 - val_loss: 1210.9494\n",
      "Epoch 80/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 1009.9191 - val_loss: 1218.7161\n",
      "Epoch 81/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 978.3984 - val_loss: 1231.6046\n",
      "Epoch 82/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 997.0346 - val_loss: 1221.5958\n",
      "Epoch 83/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 975.5809 - val_loss: 1233.3691\n",
      "Epoch 84/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 949.9524 - val_loss: 1239.7313\n",
      "Epoch 85/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 994.9213 - val_loss: 1247.9902\n",
      "Epoch 86/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 919.6172 - val_loss: 1242.3253\n",
      "Epoch 87/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 944.6499 - val_loss: 1235.1316\n",
      "Epoch 88/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 891.5031 - val_loss: 1238.6242\n",
      "Epoch 89/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 929.9356 - val_loss: 1217.9730\n",
      "Epoch 90/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 937.6879 - val_loss: 1203.4196\n",
      "Epoch 91/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 946.3546 - val_loss: 1209.5494\n",
      "Epoch 92/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 936.8183 - val_loss: 1218.1121\n",
      "Epoch 93/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 913.3366 - val_loss: 1216.1947\n",
      "Epoch 94/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 920.7527 - val_loss: 1198.4428\n",
      "Epoch 95/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 916.3299 - val_loss: 1182.5763\n",
      "Epoch 96/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 947.1820 - val_loss: 1170.9527\n",
      "Epoch 97/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 897.7874 - val_loss: 1158.3386\n",
      "Epoch 98/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 970.5086 - val_loss: 1164.3324\n",
      "Epoch 99/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 982.8845 - val_loss: 1168.8952\n",
      "Epoch 100/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 976.1795 - val_loss: 1169.5741\n",
      "Epoch 101/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 903.0213 - val_loss: 1182.7141\n",
      "Epoch 102/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 890.6752 - val_loss: 1179.9388\n",
      "Epoch 103/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 882.1035 - val_loss: 1188.4080\n",
      "Epoch 104/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 939.7479 - val_loss: 1188.9737\n",
      "Epoch 105/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 942.4970 - val_loss: 1176.7592\n",
      "Epoch 106/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 1002.2404 - val_loss: 1195.9103\n",
      "Epoch 107/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 986.8931 - val_loss: 1179.7738\n",
      "Epoch 108/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 913.9539 - val_loss: 1176.9117\n",
      "Epoch 109/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 946.4396 - val_loss: 1167.6706\n",
      "Epoch 110/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 898.6489 - val_loss: 1176.4949\n",
      "Epoch 111/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 902.9663 - val_loss: 1178.3022\n",
      "Epoch 112/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 918.7929 - val_loss: 1191.0302\n",
      "Epoch 113/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 929.3134 - val_loss: 1184.2829\n",
      "Epoch 114/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 884.9830 - val_loss: 1173.8703\n",
      "Epoch 115/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 952.3739 - val_loss: 1188.0689\n",
      "Epoch 116/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 941.9462 - val_loss: 1180.7839\n",
      "Epoch 117/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 904.4294 - val_loss: 1188.6541\n",
      "Epoch 118/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 910.2921 - val_loss: 1157.8942\n",
      "Epoch 119/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 914.6739 - val_loss: 1161.0020\n",
      "Epoch 120/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 896.7104 - val_loss: 1152.2841\n",
      "Epoch 121/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 966.1779 - val_loss: 1136.4554\n",
      "Epoch 122/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 880.3278 - val_loss: 1128.2063\n",
      "Epoch 123/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 926.2233 - val_loss: 1103.2263\n",
      "Epoch 124/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 955.3531 - val_loss: 1096.6652\n",
      "Epoch 125/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 931.4116 - val_loss: 1108.2776\n",
      "Epoch 126/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 950.1874 - val_loss: 1113.0272\n",
      "Epoch 127/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 929.5330 - val_loss: 1088.2508\n",
      "Epoch 128/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 932.2843 - val_loss: 1088.9781\n",
      "Epoch 129/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 926.9825 - val_loss: 1097.5998\n",
      "Epoch 130/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 969.3877 - val_loss: 1109.9571\n",
      "Epoch 131/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 907.3015 - val_loss: 1117.3624\n",
      "Epoch 132/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 871.1351 - val_loss: 1111.5564\n",
      "Epoch 133/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 847.9990 - val_loss: 1100.4069\n",
      "Epoch 134/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 901.7636 - val_loss: 1100.5180\n",
      "Epoch 135/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 938.6520 - val_loss: 1107.7814\n",
      "Epoch 136/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 890.1172 - val_loss: 1115.5863\n",
      "Epoch 137/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 883.1681 - val_loss: 1126.4758\n",
      "Epoch 138/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 887.8954 - val_loss: 1113.0459\n",
      "Epoch 139/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 892.9219 - val_loss: 1131.9094\n",
      "Epoch 140/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 891.3447 - val_loss: 1140.8461\n",
      "Epoch 141/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 898.0650 - val_loss: 1131.3755\n",
      "Epoch 142/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 885.3228 - val_loss: 1156.2575\n",
      "Epoch 143/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 962.4782 - val_loss: 1136.4313\n",
      "Epoch 144/500\n",
      "720/720 [==============================] - 0s 126us/step - loss: 933.6230 - val_loss: 1128.1424\n",
      "Epoch 145/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 928.9652 - val_loss: 1122.8723\n",
      "Epoch 146/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 932.2912 - val_loss: 1115.4607\n",
      "Epoch 147/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 902.5989 - val_loss: 1107.4339\n",
      "Epoch 148/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 921.7945 - val_loss: 1111.3250\n",
      "Epoch 149/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 921.0649 - val_loss: 1115.8098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 899.9433 - val_loss: 1116.6446\n",
      "Epoch 151/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 877.3615 - val_loss: 1112.0756\n",
      "Epoch 152/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 915.1846 - val_loss: 1127.4171\n",
      "Epoch 153/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 859.1127 - val_loss: 1153.8883\n",
      "Epoch 154/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 878.4882 - val_loss: 1169.2985\n",
      "Epoch 155/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 887.8974 - val_loss: 1172.1014\n",
      "Epoch 156/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 925.0502 - val_loss: 1191.5699\n",
      "Epoch 157/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 819.5151 - val_loss: 1148.9128\n",
      "Epoch 158/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 850.7389 - val_loss: 1145.2971\n",
      "Epoch 159/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 917.9164 - val_loss: 1159.7603\n",
      "Epoch 160/500\n",
      "720/720 [==============================] - 0s 128us/step - loss: 876.4682 - val_loss: 1165.5860\n",
      "Epoch 161/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 916.0336 - val_loss: 1140.9481\n",
      "Epoch 162/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 893.7034 - val_loss: 1156.0715\n",
      "Epoch 163/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 883.7276 - val_loss: 1145.8679\n",
      "Epoch 164/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 875.0558 - val_loss: 1122.6188\n",
      "Epoch 165/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 872.1752 - val_loss: 1110.4880\n",
      "Epoch 166/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 864.7430 - val_loss: 1122.3973\n",
      "Epoch 167/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 892.8357 - val_loss: 1141.0143\n",
      "Epoch 168/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 897.1970 - val_loss: 1150.1433\n",
      "Epoch 169/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 904.8323 - val_loss: 1171.2422\n",
      "Epoch 170/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 914.4749 - val_loss: 1185.5584\n",
      "Epoch 171/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 861.4647 - val_loss: 1191.1021\n",
      "Epoch 172/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 899.5474 - val_loss: 1202.7624\n",
      "Epoch 173/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 869.1361 - val_loss: 1189.1665\n",
      "Epoch 174/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 798.4668 - val_loss: 1167.7254\n",
      "Epoch 175/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 882.3997 - val_loss: 1176.6760\n",
      "Epoch 176/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 864.2541 - val_loss: 1163.1544\n",
      "Epoch 177/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 871.7425 - val_loss: 1176.5260\n",
      "Epoch 178/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 985.0237 - val_loss: 1182.9743\n",
      "Epoch 179/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 913.8321 - val_loss: 1184.3568\n",
      "Epoch 180/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 897.6114 - val_loss: 1192.2652\n",
      "Epoch 181/500\n",
      "720/720 [==============================] - 0s 129us/step - loss: 879.4309 - val_loss: 1200.1653\n",
      "Epoch 182/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 904.9273 - val_loss: 1195.9731\n",
      "Epoch 183/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 909.5769 - val_loss: 1196.8134\n",
      "Epoch 184/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 894.1788 - val_loss: 1222.0333\n",
      "Epoch 185/500\n",
      "720/720 [==============================] - 0s 122us/step - loss: 839.9937 - val_loss: 1216.7056\n",
      "Epoch 186/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 839.3952 - val_loss: 1229.1147\n",
      "Epoch 187/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 853.5981 - val_loss: 1237.8596\n",
      "Epoch 188/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 830.6461 - val_loss: 1224.2090\n",
      "Epoch 189/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 903.0088 - val_loss: 1230.5757\n",
      "Epoch 190/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 875.6651 - val_loss: 1220.2653\n",
      "Epoch 191/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 858.0030 - val_loss: 1209.1846\n",
      "Epoch 192/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 823.6744 - val_loss: 1217.0324\n",
      "Epoch 193/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 833.3804 - val_loss: 1221.8169\n",
      "Epoch 194/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 916.9423 - val_loss: 1252.0380\n",
      "Epoch 195/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 869.4122 - val_loss: 1239.1624\n",
      "Epoch 196/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 837.8485 - val_loss: 1221.7109\n",
      "Epoch 197/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 847.7615 - val_loss: 1232.3942\n",
      "Epoch 198/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 846.0529 - val_loss: 1234.3248\n",
      "Epoch 199/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 828.0078 - val_loss: 1234.9516\n",
      "Epoch 200/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 889.7910 - val_loss: 1215.1604\n",
      "Epoch 201/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 866.7376 - val_loss: 1227.4833\n",
      "Epoch 202/500\n",
      "720/720 [==============================] - 0s 125us/step - loss: 850.3913 - val_loss: 1255.1037\n",
      "Epoch 203/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 879.7254 - val_loss: 1246.6623\n",
      "Epoch 204/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 825.2459 - val_loss: 1251.7158\n",
      "Epoch 205/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 811.8839 - val_loss: 1227.8249\n",
      "Epoch 206/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 880.8172 - val_loss: 1235.9628\n",
      "Epoch 207/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 809.0937 - val_loss: 1234.6244\n",
      "Epoch 208/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 890.8360 - val_loss: 1246.0045\n",
      "Epoch 209/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 871.3361 - val_loss: 1262.7963\n",
      "Epoch 210/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 937.8059 - val_loss: 1277.2024\n",
      "Epoch 211/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 900.6701 - val_loss: 1271.5047\n",
      "Epoch 212/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 920.1978 - val_loss: 1254.2624\n",
      "Epoch 213/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 859.8085 - val_loss: 1278.6943\n",
      "Epoch 214/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 925.0030 - val_loss: 1261.9605\n",
      "Epoch 215/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 889.6193 - val_loss: 1277.2977\n",
      "Epoch 216/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 831.5655 - val_loss: 1284.9596\n",
      "Epoch 217/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 829.6574 - val_loss: 1281.9102\n",
      "Epoch 218/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 881.2372 - val_loss: 1258.3592\n",
      "Epoch 219/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 791.4661 - val_loss: 1230.4760\n",
      "Epoch 220/500\n",
      "720/720 [==============================] - 0s 124us/step - loss: 859.2697 - val_loss: 1220.5555\n",
      "Epoch 221/500\n",
      "720/720 [==============================] - 0s 128us/step - loss: 886.1439 - val_loss: 1242.7517\n",
      "Epoch 222/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 817.5749 - val_loss: 1235.7185\n",
      "Epoch 223/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 851.4725 - val_loss: 1250.1437\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 115us/step - loss: 849.1819 - val_loss: 1258.0597\n",
      "Epoch 225/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 775.9842 - val_loss: 1267.7000\n",
      "Epoch 226/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 881.2082 - val_loss: 1261.6093\n",
      "Epoch 227/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 791.0114 - val_loss: 1270.8218\n",
      "Epoch 228/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 889.0798 - val_loss: 1263.6455\n",
      "Epoch 229/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 917.4937 - val_loss: 1257.8609\n",
      "Epoch 230/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 884.5444 - val_loss: 1257.1067\n",
      "Epoch 231/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 831.3822 - val_loss: 1235.8881\n",
      "Epoch 232/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 879.6756 - val_loss: 1231.9153\n",
      "Epoch 233/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 820.3275 - val_loss: 1239.4875\n",
      "Epoch 234/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 873.1226 - val_loss: 1238.6396\n",
      "Epoch 235/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 801.5150 - val_loss: 1229.8787\n",
      "Epoch 236/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 897.9531 - val_loss: 1222.8457\n",
      "Epoch 237/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 803.6210 - val_loss: 1231.8577\n",
      "Epoch 238/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 850.5055 - val_loss: 1249.8322\n",
      "Epoch 239/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 833.4073 - val_loss: 1253.2746\n",
      "Epoch 240/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 865.1617 - val_loss: 1287.7593\n",
      "Epoch 241/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 873.5538 - val_loss: 1273.3283\n",
      "Epoch 242/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 847.5281 - val_loss: 1269.8552\n",
      "Epoch 243/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 880.2998 - val_loss: 1277.3932\n",
      "Epoch 244/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 830.8537 - val_loss: 1254.5614\n",
      "Epoch 245/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 840.8950 - val_loss: 1283.2776\n",
      "Epoch 246/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 849.3732 - val_loss: 1278.4272\n",
      "Epoch 247/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 833.8511 - val_loss: 1286.5102\n",
      "Epoch 248/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 891.3958 - val_loss: 1291.8925\n",
      "Epoch 249/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 837.4690 - val_loss: 1313.2279\n",
      "Epoch 250/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 850.1453 - val_loss: 1355.6987\n",
      "Epoch 251/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 853.4471 - val_loss: 1385.7265\n",
      "Epoch 252/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 825.0554 - val_loss: 1369.3101\n",
      "Epoch 253/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 867.6300 - val_loss: 1319.8509\n",
      "Epoch 254/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 815.1461 - val_loss: 1338.5969\n",
      "Epoch 255/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 847.3952 - val_loss: 1317.5033\n",
      "Epoch 256/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 832.4221 - val_loss: 1315.5274\n",
      "Epoch 257/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 853.2055 - val_loss: 1304.8623\n",
      "Epoch 258/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 800.2763 - val_loss: 1298.0587\n",
      "Epoch 259/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 813.0153 - val_loss: 1355.3234\n",
      "Epoch 260/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 876.3846 - val_loss: 1331.3786\n",
      "Epoch 261/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 775.4571 - val_loss: 1334.8682\n",
      "Epoch 262/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 826.6086 - val_loss: 1344.4888\n",
      "Epoch 263/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 820.4083 - val_loss: 1319.5422\n",
      "Epoch 264/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 834.1106 - val_loss: 1335.8898\n",
      "Epoch 265/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 802.6956 - val_loss: 1316.5581\n",
      "Epoch 266/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 918.4818 - val_loss: 1320.1276\n",
      "Epoch 267/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 801.5277 - val_loss: 1332.5409\n",
      "Epoch 268/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 838.0822 - val_loss: 1341.1199\n",
      "Epoch 269/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 881.8898 - val_loss: 1337.0284\n",
      "Epoch 270/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 834.3581 - val_loss: 1349.4937\n",
      "Epoch 271/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 831.7789 - val_loss: 1368.4857\n",
      "Epoch 272/500\n",
      "720/720 [==============================] - 0s 106us/step - loss: 861.1693 - val_loss: 1353.6110\n",
      "Epoch 273/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 896.5786 - val_loss: 1352.4529\n",
      "Epoch 274/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 893.3113 - val_loss: 1359.4208\n",
      "Epoch 275/500\n",
      "720/720 [==============================] - 0s 123us/step - loss: 840.1348 - val_loss: 1358.2749\n",
      "Epoch 276/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 859.7144 - val_loss: 1382.8572\n",
      "Epoch 277/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 882.9060 - val_loss: 1367.6157\n",
      "Epoch 278/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 854.2247 - val_loss: 1391.6683\n",
      "Epoch 279/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 867.4055 - val_loss: 1356.3155\n",
      "Epoch 280/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 885.2971 - val_loss: 1357.3408\n",
      "Epoch 281/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 833.3414 - val_loss: 1366.4556\n",
      "Epoch 282/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 832.9589 - val_loss: 1390.4404\n",
      "Epoch 283/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 855.5454 - val_loss: 1358.9746\n",
      "Epoch 284/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 827.3622 - val_loss: 1360.0207\n",
      "Epoch 285/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 860.8127 - val_loss: 1416.3728\n",
      "Epoch 286/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 853.6757 - val_loss: 1367.4560\n",
      "Epoch 287/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 850.6764 - val_loss: 1355.9384\n",
      "Epoch 288/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 823.5673 - val_loss: 1360.5058\n",
      "Epoch 289/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 831.9650 - val_loss: 1372.3511\n",
      "Epoch 290/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 819.6917 - val_loss: 1392.2515\n",
      "Epoch 291/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 846.5036 - val_loss: 1365.3315\n",
      "Epoch 292/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 799.1288 - val_loss: 1341.3660\n",
      "Epoch 293/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 814.0483 - val_loss: 1366.4036\n",
      "Epoch 294/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 837.8621 - val_loss: 1320.1027\n",
      "Epoch 295/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 796.1083 - val_loss: 1257.4542\n",
      "Epoch 296/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 786.5637 - val_loss: 1295.5285\n",
      "Epoch 297/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 848.1132 - val_loss: 1322.4358\n",
      "Epoch 298/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 113us/step - loss: 821.1479 - val_loss: 1313.3203\n",
      "Epoch 299/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 812.1213 - val_loss: 1340.1205\n",
      "Epoch 300/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 850.0608 - val_loss: 1305.5703\n",
      "Epoch 301/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 847.4292 - val_loss: 1323.3090\n",
      "Epoch 302/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 777.8281 - val_loss: 1353.2374\n",
      "Epoch 303/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 855.7275 - val_loss: 1343.5935\n",
      "Epoch 304/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 811.4160 - val_loss: 1368.9639\n",
      "Epoch 305/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 838.7081 - val_loss: 1375.8673\n",
      "Epoch 306/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 771.6778 - val_loss: 1402.6417\n",
      "Epoch 307/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 821.2275 - val_loss: 1411.5562\n",
      "Epoch 308/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 792.5467 - val_loss: 1419.9077\n",
      "Epoch 309/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 817.2441 - val_loss: 1451.9114\n",
      "Epoch 310/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 836.4438 - val_loss: 1453.0527\n",
      "Epoch 311/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 793.9796 - val_loss: 1442.9668\n",
      "Epoch 312/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 870.5477 - val_loss: 1441.7190\n",
      "Epoch 313/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 776.9597 - val_loss: 1516.9939\n",
      "Epoch 314/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 808.0911 - val_loss: 1498.8218\n",
      "Epoch 315/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 834.5299 - val_loss: 1493.2387\n",
      "Epoch 316/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 879.5344 - val_loss: 1479.8730\n",
      "Epoch 317/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 819.9320 - val_loss: 1516.4401\n",
      "Epoch 318/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 864.9962 - val_loss: 1519.8292\n",
      "Epoch 319/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 851.2944 - val_loss: 1549.2837\n",
      "Epoch 320/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 765.6327 - val_loss: 1578.1985\n",
      "Epoch 321/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 894.5510 - val_loss: 1610.6795\n",
      "Epoch 322/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 787.0055 - val_loss: 1483.9487\n",
      "Epoch 323/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 852.2647 - val_loss: 1476.1000\n",
      "Epoch 324/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 829.7319 - val_loss: 1508.5301\n",
      "Epoch 325/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 860.8519 - val_loss: 1587.1639\n",
      "Epoch 326/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 829.6113 - val_loss: 1596.7358\n",
      "Epoch 327/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 775.7191 - val_loss: 1602.0933\n",
      "Epoch 328/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 871.6634 - val_loss: 1625.8574\n",
      "Epoch 329/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 772.4088 - val_loss: 1602.4278\n",
      "Epoch 330/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 855.6467 - val_loss: 1549.9339\n",
      "Epoch 331/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 791.2313 - val_loss: 1555.8086\n",
      "Epoch 332/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 864.4148 - val_loss: 1522.7883\n",
      "Epoch 333/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 775.7433 - val_loss: 1468.7311\n",
      "Epoch 334/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 897.0845 - val_loss: 1459.8486\n",
      "Epoch 335/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 770.7826 - val_loss: 1479.4039\n",
      "Epoch 336/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 833.8620 - val_loss: 1495.7753\n",
      "Epoch 337/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 846.0362 - val_loss: 1502.1765\n",
      "Epoch 338/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 829.6931 - val_loss: 1477.0671\n",
      "Epoch 339/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 833.4689 - val_loss: 1508.3770\n",
      "Epoch 340/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 799.9104 - val_loss: 1497.6434\n",
      "Epoch 341/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 822.5491 - val_loss: 1486.0513\n",
      "Epoch 342/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 806.7587 - val_loss: 1537.1045\n",
      "Epoch 343/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 764.9340 - val_loss: 1562.0594\n",
      "Epoch 344/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 824.6636 - val_loss: 1608.7044\n",
      "Epoch 345/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 826.0395 - val_loss: 1585.2318\n",
      "Epoch 346/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 786.7891 - val_loss: 1576.7716\n",
      "Epoch 347/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 801.5821 - val_loss: 1577.0847\n",
      "Epoch 348/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 830.9171 - val_loss: 1555.0991\n",
      "Epoch 349/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 809.5604 - val_loss: 1575.7182\n",
      "Epoch 350/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 850.3129 - val_loss: 1555.1467\n",
      "Epoch 351/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 865.6861 - val_loss: 1539.8500\n",
      "Epoch 352/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 809.0612 - val_loss: 1545.6933\n",
      "Epoch 353/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 827.8174 - val_loss: 1566.0449\n",
      "Epoch 354/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 854.7693 - val_loss: 1555.9852\n",
      "Epoch 355/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 827.9964 - val_loss: 1530.3816\n",
      "Epoch 356/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 753.1941 - val_loss: 1556.3562\n",
      "Epoch 357/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 840.8079 - val_loss: 1494.9565\n",
      "Epoch 358/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 799.9680 - val_loss: 1499.4809\n",
      "Epoch 359/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 826.6582 - val_loss: 1469.4514\n",
      "Epoch 360/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 831.2695 - val_loss: 1442.9164\n",
      "Epoch 361/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 843.3567 - val_loss: 1438.3524\n",
      "Epoch 362/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 814.5926 - val_loss: 1428.0172\n",
      "Epoch 363/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 818.2790 - val_loss: 1486.3946\n",
      "Epoch 364/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 826.9199 - val_loss: 1476.1627\n",
      "Epoch 365/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 775.3330 - val_loss: 1489.7919\n",
      "Epoch 366/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 814.3480 - val_loss: 1452.8383\n",
      "Epoch 367/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 784.4397 - val_loss: 1460.5391\n",
      "Epoch 368/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 844.4767 - val_loss: 1425.5779\n",
      "Epoch 369/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 778.3782 - val_loss: 1378.6727\n",
      "Epoch 370/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 838.4270 - val_loss: 1380.4262\n",
      "Epoch 371/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 873.8438 - val_loss: 1424.7825\n",
      "Epoch 372/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 116us/step - loss: 801.0080 - val_loss: 1382.1195\n",
      "Epoch 373/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 802.2157 - val_loss: 1395.7902\n",
      "Epoch 374/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 783.7402 - val_loss: 1420.3997\n",
      "Epoch 375/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 818.9330 - val_loss: 1417.2743\n",
      "Epoch 376/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 812.7112 - val_loss: 1477.0469\n",
      "Epoch 377/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 819.1987 - val_loss: 1448.7608\n",
      "Epoch 378/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 800.9647 - val_loss: 1474.2303\n",
      "Epoch 379/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 825.3474 - val_loss: 1461.7796\n",
      "Epoch 380/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 797.5283 - val_loss: 1467.3540\n",
      "Epoch 381/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 787.2295 - val_loss: 1456.2262\n",
      "Epoch 382/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 804.2813 - val_loss: 1467.5660\n",
      "Epoch 383/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 784.9249 - val_loss: 1489.1224\n",
      "Epoch 384/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 777.8425 - val_loss: 1487.6568\n",
      "Epoch 385/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 820.2880 - val_loss: 1454.1713\n",
      "Epoch 386/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 791.8380 - val_loss: 1496.4139\n",
      "Epoch 387/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 866.8057 - val_loss: 1497.9260\n",
      "Epoch 388/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 819.0268 - val_loss: 1511.6128\n",
      "Epoch 389/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 807.5700 - val_loss: 1490.9236\n",
      "Epoch 390/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 828.1684 - val_loss: 1526.2417\n",
      "Epoch 391/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 770.2996 - val_loss: 1487.0192\n",
      "Epoch 392/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 819.2202 - val_loss: 1491.0848\n",
      "Epoch 393/500\n",
      "720/720 [==============================] - 0s 107us/step - loss: 858.9450 - val_loss: 1520.4671\n",
      "Epoch 394/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 825.4210 - val_loss: 1480.7478\n",
      "Epoch 395/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 871.4117 - val_loss: 1493.3659\n",
      "Epoch 396/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 845.2107 - val_loss: 1481.8860\n",
      "Epoch 397/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 835.3653 - val_loss: 1469.9768\n",
      "Epoch 398/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 862.7019 - val_loss: 1478.4904\n",
      "Epoch 399/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 762.3286 - val_loss: 1488.6604\n",
      "Epoch 400/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 817.3775 - val_loss: 1479.7031\n",
      "Epoch 401/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 789.0106 - val_loss: 1420.8826\n",
      "Epoch 402/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 837.9429 - val_loss: 1439.8637\n",
      "Epoch 403/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 866.6805 - val_loss: 1423.3076\n",
      "Epoch 404/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 796.8088 - val_loss: 1399.5103\n",
      "Epoch 405/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 781.6551 - val_loss: 1408.1829\n",
      "Epoch 406/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 772.3024 - val_loss: 1387.4973\n",
      "Epoch 407/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 756.9786 - val_loss: 1337.0660\n",
      "Epoch 408/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 821.6962 - val_loss: 1339.5949\n",
      "Epoch 409/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 804.6585 - val_loss: 1333.8018\n",
      "Epoch 410/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 777.9437 - val_loss: 1354.9615\n",
      "Epoch 411/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 724.1298 - val_loss: 1323.3850\n",
      "Epoch 412/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 789.3975 - val_loss: 1353.4936\n",
      "Epoch 413/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 851.6257 - val_loss: 1361.6560\n",
      "Epoch 414/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 780.8932 - val_loss: 1378.6912\n",
      "Epoch 415/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 818.2832 - val_loss: 1353.8792\n",
      "Epoch 416/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 835.0982 - val_loss: 1353.7523\n",
      "Epoch 417/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 801.2916 - val_loss: 1330.0349\n",
      "Epoch 418/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 771.2664 - val_loss: 1251.4521\n",
      "Epoch 419/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 787.6002 - val_loss: 1235.4018\n",
      "Epoch 420/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 883.3495 - val_loss: 1263.9291\n",
      "Epoch 421/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 755.1491 - val_loss: 1262.4726\n",
      "Epoch 422/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 826.1615 - val_loss: 1249.6937\n",
      "Epoch 423/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 850.0926 - val_loss: 1259.2580\n",
      "Epoch 424/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 836.5520 - val_loss: 1236.4817\n",
      "Epoch 425/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 805.6458 - val_loss: 1257.0580\n",
      "Epoch 426/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 814.5572 - val_loss: 1276.9311\n",
      "Epoch 427/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 809.1763 - val_loss: 1289.7830\n",
      "Epoch 428/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 806.4749 - val_loss: 1278.7005\n",
      "Epoch 429/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 788.8434 - val_loss: 1307.5857\n",
      "Epoch 430/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 805.8556 - val_loss: 1285.7353\n",
      "Epoch 431/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 843.9632 - val_loss: 1260.8344\n",
      "Epoch 432/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 805.1698 - val_loss: 1261.9909\n",
      "Epoch 433/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 769.6973 - val_loss: 1298.2247\n",
      "Epoch 434/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 791.6752 - val_loss: 1290.2265\n",
      "Epoch 435/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 850.1992 - val_loss: 1305.8887\n",
      "Epoch 436/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 816.0321 - val_loss: 1346.2484\n",
      "Epoch 437/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 817.7523 - val_loss: 1365.6124\n",
      "Epoch 438/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 797.6548 - val_loss: 1333.1906\n",
      "Epoch 439/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 818.3616 - val_loss: 1327.8442\n",
      "Epoch 440/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 761.3422 - val_loss: 1334.2464\n",
      "Epoch 441/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 809.5768 - val_loss: 1349.2380\n",
      "Epoch 442/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 787.6631 - val_loss: 1376.3972\n",
      "Epoch 443/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 803.1810 - val_loss: 1382.2068\n",
      "Epoch 444/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 822.5161 - val_loss: 1372.4910\n",
      "Epoch 445/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 794.4032 - val_loss: 1342.0795\n",
      "Epoch 446/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 121us/step - loss: 823.2158 - val_loss: 1343.2473\n",
      "Epoch 447/500\n",
      "720/720 [==============================] - 0s 115us/step - loss: 799.9375 - val_loss: 1316.3485\n",
      "Epoch 448/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 772.8780 - val_loss: 1318.3064\n",
      "Epoch 449/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 843.2159 - val_loss: 1367.1424\n",
      "Epoch 450/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 810.0200 - val_loss: 1364.4592\n",
      "Epoch 451/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 789.5862 - val_loss: 1320.1969\n",
      "Epoch 452/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 740.8231 - val_loss: 1351.8695\n",
      "Epoch 453/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 827.8130 - val_loss: 1313.4710\n",
      "Epoch 454/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 798.3577 - val_loss: 1307.4139\n",
      "Epoch 455/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 812.8994 - val_loss: 1326.9445\n",
      "Epoch 456/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 833.4435 - val_loss: 1350.9971\n",
      "Epoch 457/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 828.4246 - val_loss: 1334.9963\n",
      "Epoch 458/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 767.1978 - val_loss: 1324.0904\n",
      "Epoch 459/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 835.6758 - val_loss: 1343.8461\n",
      "Epoch 460/500\n",
      "720/720 [==============================] - 0s 119us/step - loss: 776.8921 - val_loss: 1346.3791\n",
      "Epoch 461/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 826.3489 - val_loss: 1382.9231\n",
      "Epoch 462/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 834.9979 - val_loss: 1392.3797\n",
      "Epoch 463/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 770.5664 - val_loss: 1375.7886\n",
      "Epoch 464/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 792.8102 - val_loss: 1286.7758\n",
      "Epoch 465/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 875.6929 - val_loss: 1304.0073\n",
      "Epoch 466/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 826.7164 - val_loss: 1282.5978\n",
      "Epoch 467/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 801.7600 - val_loss: 1289.4101\n",
      "Epoch 468/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 906.5733 - val_loss: 1291.5223\n",
      "Epoch 469/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 846.7271 - val_loss: 1295.4404\n",
      "Epoch 470/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 811.1625 - val_loss: 1257.5734\n",
      "Epoch 471/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 810.4351 - val_loss: 1292.6189\n",
      "Epoch 472/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 829.7746 - val_loss: 1319.3062\n",
      "Epoch 473/500\n",
      "720/720 [==============================] - 0s 120us/step - loss: 802.8423 - val_loss: 1325.9043\n",
      "Epoch 474/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 754.6596 - val_loss: 1326.0892\n",
      "Epoch 475/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 805.9622 - val_loss: 1326.2362\n",
      "Epoch 476/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 765.1516 - val_loss: 1310.8410\n",
      "Epoch 477/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 732.6077 - val_loss: 1296.5185\n",
      "Epoch 478/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 806.6203 - val_loss: 1294.6585\n",
      "Epoch 479/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 748.0407 - val_loss: 1344.6861\n",
      "Epoch 480/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 775.9708 - val_loss: 1353.4166\n",
      "Epoch 481/500\n",
      "720/720 [==============================] - 0s 117us/step - loss: 775.0718 - val_loss: 1347.5382\n",
      "Epoch 482/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 833.0265 - val_loss: 1324.2592\n",
      "Epoch 483/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 812.8113 - val_loss: 1335.8452\n",
      "Epoch 484/500\n",
      "720/720 [==============================] - 0s 116us/step - loss: 778.6333 - val_loss: 1349.7725\n",
      "Epoch 485/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 841.6929 - val_loss: 1364.5817\n",
      "Epoch 486/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 808.7780 - val_loss: 1418.1954\n",
      "Epoch 487/500\n",
      "720/720 [==============================] - 0s 111us/step - loss: 796.4127 - val_loss: 1444.2758\n",
      "Epoch 488/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 838.3083 - val_loss: 1478.0226\n",
      "Epoch 489/500\n",
      "720/720 [==============================] - 0s 108us/step - loss: 802.0728 - val_loss: 1467.8140\n",
      "Epoch 490/500\n",
      "720/720 [==============================] - 0s 121us/step - loss: 808.1670 - val_loss: 1464.2514\n",
      "Epoch 491/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 849.0516 - val_loss: 1427.4331\n",
      "Epoch 492/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 767.2720 - val_loss: 1419.1407\n",
      "Epoch 493/500\n",
      "720/720 [==============================] - 0s 112us/step - loss: 822.4996 - val_loss: 1448.4194\n",
      "Epoch 494/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 777.9173 - val_loss: 1428.1377\n",
      "Epoch 495/500\n",
      "720/720 [==============================] - 0s 109us/step - loss: 801.6488 - val_loss: 1427.5714\n",
      "Epoch 496/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 871.8972 - val_loss: 1439.0228\n",
      "Epoch 497/500\n",
      "720/720 [==============================] - 0s 110us/step - loss: 732.9788 - val_loss: 1475.4722\n",
      "Epoch 498/500\n",
      "720/720 [==============================] - 0s 114us/step - loss: 818.6122 - val_loss: 1444.3285\n",
      "Epoch 499/500\n",
      "720/720 [==============================] - 0s 118us/step - loss: 782.7998 - val_loss: 1424.5491\n",
      "Epoch 500/500\n",
      "720/720 [==============================] - 0s 113us/step - loss: 746.0816 - val_loss: 1411.1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f0b722908>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train, y_train, epochs=500, verbose =1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.losses\n",
    "\n",
    "keras.losses.root_mean_squared_error = root_mean_squared_error\n",
    "\n",
    "model_3 = load_model('./reg_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_out(reg_list, model_list, X_valid):\n",
    "    y1 = model_list[0].predict(X_valid)\n",
    "    y2 = model_list[1].predict(X_valid)\n",
    "    y3 = model_list[2].predict(X_valid)\n",
    "    y4 = reg_list[0].predict(X_valid).reshape(-1,1)\n",
    "    y5 = reg_list[1].predict(X_valid).reshape(-1,1)\n",
    "    y6 = reg_list[2].predict(X_valid).reshape(-1,1)\n",
    "    \n",
    "    y_new = np.array([y1,y2,y3,y4,y5,y6])\n",
    "    \n",
    "    #rint(y4.shape)\n",
    "    return np.mean(y_new, axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2359.41850521],\n",
       "       [2791.14429071],\n",
       "       [2975.1801124 ],\n",
       "       [3137.2384246 ],\n",
       "       [2556.04705343],\n",
       "       [5055.77553146],\n",
       "       [6723.42994094],\n",
       "       [2567.28632152],\n",
       "       [2488.15045216],\n",
       "       [2897.53206982],\n",
       "       [3497.3427324 ],\n",
       "       [5016.5338238 ],\n",
       "       [2069.47720622],\n",
       "       [2585.3088388 ],\n",
       "       [1604.61149194],\n",
       "       [2772.20738258],\n",
       "       [1977.82577556],\n",
       "       [2379.9681289 ],\n",
       "       [2112.9859861 ],\n",
       "       [2174.00779515],\n",
       "       [2714.63645701],\n",
       "       [2286.12394212],\n",
       "       [2773.13964649],\n",
       "       [1971.94887259],\n",
       "       [3844.7672149 ],\n",
       "       [2214.8403474 ],\n",
       "       [2796.00151588],\n",
       "       [3601.68948852],\n",
       "       [3063.26981028],\n",
       "       [2296.57137321],\n",
       "       [2205.17737502],\n",
       "       [2397.15729664],\n",
       "       [2382.88932405],\n",
       "       [2659.88889292],\n",
       "       [2827.22703197],\n",
       "       [2468.36729527],\n",
       "       [2457.18853922],\n",
       "       [2842.91811903],\n",
       "       [2717.99046389],\n",
       "       [2676.12720008],\n",
       "       [2352.29612162],\n",
       "       [2274.79358913],\n",
       "       [2826.94977413],\n",
       "       [2416.79365611],\n",
       "       [4601.12938054],\n",
       "       [3102.01480672],\n",
       "       [2200.58568098],\n",
       "       [6014.95774052],\n",
       "       [2942.70520409],\n",
       "       [2166.37439187],\n",
       "       [3424.15643938],\n",
       "       [3065.05695111],\n",
       "       [3234.84207259],\n",
       "       [2868.99239665],\n",
       "       [2065.02395348],\n",
       "       [2984.44075453],\n",
       "       [2042.66981318],\n",
       "       [3218.25259636],\n",
       "       [5285.94040601],\n",
       "       [1698.74461128],\n",
       "       [2224.34685304],\n",
       "       [2266.9557089 ],\n",
       "       [1558.92858391],\n",
       "       [5067.98281972],\n",
       "       [2217.17375711],\n",
       "       [2210.27662269],\n",
       "       [2571.6462428 ],\n",
       "       [2690.73105758],\n",
       "       [2176.43674086],\n",
       "       [3325.68597896],\n",
       "       [2530.97357831],\n",
       "       [2923.79484636],\n",
       "       [2712.02411047],\n",
       "       [3475.30964448],\n",
       "       [3141.18610161],\n",
       "       [2166.19751113],\n",
       "       [2540.41866359],\n",
       "       [2225.72810943],\n",
       "       [2429.15379562],\n",
       "       [2606.04414875]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = average_out(classifier_list, [model, model_2, model_3] , X_valid)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./reg_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = reorder_columns(val_cols,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = pd.get_dummies(test_df, columns = obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = drop_columns(new_test_df, columns_to_be_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 60)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(new_test_df)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 60)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scale.transform(X_test)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = average_out(classifier_list,[model,model_2, model_3] , X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = scale_y.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(pred_test, filename):\n",
    "    df = pd.read_csv('sample_reg.csv')\n",
    "    df['credit_amount'] = pred_test\n",
    "    df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(y_pred_new, 'regression_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_labels(row):\n",
    "#for row in new_df.itertuples():\n",
    "    #print(row.credit_amount)\n",
    "    if(row < 1500):\n",
    "        return 3\n",
    "    elif(row >= 1500 and row < 4000):\n",
    "        return 2\n",
    "    elif (row >= 4000 and row < 20000):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv_new( filename):\n",
    "    df = pd.read_csv('regression_v3.csv')\n",
    "    df['cluster_number'] = df['credit_amount'].apply(get_classification_labels)\n",
    "    df = df.drop(columns=['credit_amount'])\n",
    "    df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_new('classification_v2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
